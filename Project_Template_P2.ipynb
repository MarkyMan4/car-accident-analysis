{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Template: Phase 2\n",
    "\n",
    "Below are some concrete steps that you can take while doing your analysis for phase3. This guide isn't \"one size fit all\" so you will probably not do everything listed. But it still serves as a good \"pipeline\" for how to do data analysis.\n",
    "\n",
    "If you do engage in a step, you should clearly mention it in the notebook.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Decide on what models you will use and compare\n",
    "\n",
    "Select at least 3 models to compare on your prediction task. At least 2 of your models should be ones we've covered in class. \n",
    "\n",
    "Some resources try to help you select a well-performing model for your data:\n",
    "* [sklearn's Flowchart](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)\n",
    "* [geeks4geeks Flowchart](https://www.geeksforgeeks.org/flowchart-for-basic-machine-learning-models/)\n",
    "* [SAS Cheatsheet](https://blogs.sas.com/content/subconsciousmusings/files/2017/04/machine-learning-cheet-sheet.png)\n",
    "\n",
    "**Note**: These are general guides, and not guarantees of success. Some of the models are also outside of what we have covered, but you can explore them if you want to.\n",
    "\n",
    "In addition to selecting a model you think will perform well, there are other reasons to select a model:\n",
    "* To serve as a baseline (naive) approach you expect to outperform with more complex/appropriate models.\n",
    "* You need a model that is human interpretable (e.g. Decision Tree).\n",
    "* The model has historically performed well on similar tasks.\n",
    "* Some properties of the model are effective for the type of data you have. Remember, at the end of most Seminars, you learned the strengths and weaknesses of each model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Model Decision tree classifier: I am selecting Decision tree classifier because...\n",
    "2. AdaBoost classifier : I am selecting K Neighbors classifier because...\n",
    "3. Model ANN: I am selecting ANN because...\n",
    "\n",
    "I'm not sure exactly why I'll be using each of these models yet. I'm still learning so my plan is to experiment with these various classifiers to help develop an intution for what works best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Split into train and test\n",
    "Make sure to split your data *before* you apply any transformations.\n",
    "\n",
    "**Note**: If you have multiple records from the same object (e.g., multiple attempts from the same student), these should all go in either training or test, but not split between them. See the examples for how to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Severity</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Wind_Chill(F)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Pressure(in)</th>\n",
       "      <th>Visibility(mi)</th>\n",
       "      <th>Wind_Speed(mph)</th>\n",
       "      <th>Precipitation(in)</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>...</th>\n",
       "      <th>start_month</th>\n",
       "      <th>start_day</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_minute</th>\n",
       "      <th>start_second</th>\n",
       "      <th>end_month</th>\n",
       "      <th>end_day</th>\n",
       "      <th>end_hour</th>\n",
       "      <th>end_minute</th>\n",
       "      <th>end_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3.230</td>\n",
       "      <td>42.1</td>\n",
       "      <td>36.1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>29.76</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.747</td>\n",
       "      <td>36.9</td>\n",
       "      <td>36.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>29.68</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>56</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.055</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>29.70</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.123</td>\n",
       "      <td>39.0</td>\n",
       "      <td>36.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>29.65</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.500</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.8</td>\n",
       "      <td>93.0</td>\n",
       "      <td>29.69</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>53</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845337</th>\n",
       "      <td>2</td>\n",
       "      <td>0.543</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>28.92</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845338</th>\n",
       "      <td>2</td>\n",
       "      <td>0.338</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>29.39</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845339</th>\n",
       "      <td>2</td>\n",
       "      <td>0.561</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>29.74</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845340</th>\n",
       "      <td>2</td>\n",
       "      <td>0.772</td>\n",
       "      <td>71.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>29.62</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845341</th>\n",
       "      <td>2</td>\n",
       "      <td>0.537</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>28.63</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2845342 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Severity  Distance(mi)  Temperature(F)  Wind_Chill(F)  Humidity(%)  \\\n",
       "0               3         3.230            42.1           36.1         58.0   \n",
       "1               2         0.747            36.9           36.1         91.0   \n",
       "2               2         0.055            36.0           36.1         97.0   \n",
       "3               2         0.123            39.0           36.1         55.0   \n",
       "4               3         0.500            37.0           29.8         93.0   \n",
       "...           ...           ...             ...            ...          ...   \n",
       "2845337         2         0.543            86.0           86.0         40.0   \n",
       "2845338         2         0.338            70.0           70.0         73.0   \n",
       "2845339         2         0.561            73.0           73.0         64.0   \n",
       "2845340         2         0.772            71.0           71.0         81.0   \n",
       "2845341         2         0.537            79.0           79.0         47.0   \n",
       "\n",
       "         Pressure(in)  Visibility(mi)  Wind_Speed(mph)  Precipitation(in)  \\\n",
       "0               29.76            10.0             10.4               0.00   \n",
       "1               29.68            10.0             10.4               0.02   \n",
       "2               29.70            10.0             10.4               0.02   \n",
       "3               29.65            10.0             10.4               0.02   \n",
       "4               29.69            10.0             10.4               0.01   \n",
       "...               ...             ...              ...                ...   \n",
       "2845337         28.92            10.0             13.0               0.00   \n",
       "2845338         29.39            10.0              6.0               0.00   \n",
       "2845339         29.74            10.0             10.0               0.00   \n",
       "2845340         29.62            10.0              8.0               0.00   \n",
       "2845341         28.63             7.0              7.0               0.00   \n",
       "\n",
       "         Sunrise_Sunset  ...  start_month  start_day  start_hour  \\\n",
       "0                   1.0  ...            2          8           0   \n",
       "1                   1.0  ...            2          8           5   \n",
       "2                   1.0  ...            2          8           6   \n",
       "3                   1.0  ...            2          8           6   \n",
       "4                   0.0  ...            2          8           7   \n",
       "...                 ...  ...          ...        ...         ...   \n",
       "2845337             0.0  ...            8         23          18   \n",
       "2845338             0.0  ...            8         23          19   \n",
       "2845339             0.0  ...            8         23          19   \n",
       "2845340             0.0  ...            8         23          19   \n",
       "2845341             0.0  ...            8         23          18   \n",
       "\n",
       "         start_minute  start_second  end_month  end_day  end_hour  end_minute  \\\n",
       "0                  37             8          2        8         6          37   \n",
       "1                  56            20          2        8        11          56   \n",
       "2                  15            39          2        8        12          15   \n",
       "3                  51            45          2        8        12          51   \n",
       "4                  53            43          2        8        13          53   \n",
       "...               ...           ...        ...      ...       ...         ...   \n",
       "2845337             3            25          8       23        18          32   \n",
       "2845338            11            30          8       23        19          38   \n",
       "2845339             0            21          8       23        19          28   \n",
       "2845340             0            21          8       23        19          29   \n",
       "2845341            52             6          8       23        19          21   \n",
       "\n",
       "         end_second  \n",
       "0                 8  \n",
       "1                20  \n",
       "2                39  \n",
       "3                45  \n",
       "4                43  \n",
       "...             ...  \n",
       "2845337           1  \n",
       "2845338          23  \n",
       "2845339          49  \n",
       "2845340          42  \n",
       "2845341          31  \n",
       "\n",
       "[2845342 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/clean.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Severity']\n",
    "X = df.drop(columns=['Severity'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1) Sampling (If needed)\n",
    "\n",
    "If one of your classes is very underrepresented (e.g. 1000 of Class 0; 200 of Class 1), you might consider oversampling the minority class (e.g. sample 1000 times with replacement from 200 instances), or undersampling the majority class (e.g. sample 200 times from 1000 instances).\n",
    "\n",
    "Check out [np.random.choice](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) for how to sample a vector.\n",
    "\n",
    "**Note 1**: You should only ever sample the *training dataset*, never the test. After all, you can't chose the class distribution of your test data!\n",
    "\n",
    "**Note 2**: Sampling can help a classifier perform better on the minority class, often at the cost of *overall* performance. But this is no guarantee. If you chose to sample, you should compare your classifiers' performance with and without sampling to see if it actually helped.\n",
    "\n",
    "**Note 3**: Make sure you sample the *same* indices from your training and test data -- otherwise they won't match anymore!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with sampling below (or skip this step if you don't need sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('Severity').apply(lambda x: x.sample(frac=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " When you're done, write the `sample_data` method to perform sampling on any training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Input: The original X_train and Y_train training dataset\n",
    "    Output: A new training dataset with sampling applied (same columns, different rows)\n",
    "    \"\"\"\n",
    "    # For example, undersample the majority class, or oversample the minority class.\n",
    "    \n",
    "    return (X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your training data to fit any transformers or encoder your need, then apply the fit transformer to your test data. This applies to:\n",
    "* Normalizing/standardizing your features\n",
    "* Using Bag of Words or TF-IDF to encode strings\n",
    "* PCA or dimensionality reduction\n",
    "\n",
    "**Rationale**: In practice, we won't be able to see the test data we'll be making predicting for, so we shouldn't use that data as the basis for any transformation or feature extractio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your feature transformation below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " When you're done, write the `apply_feature_transformation` method to perform transformation on any training/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_transformation(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Input: The original X_train and X_test feature sets.\n",
    "    Output: The transformed X_train and X_test feature sets.\n",
    "\n",
    "    Scaling features\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = apply_feature_transformation(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4) Train and Explore your Models\n",
    "Using the models you decided upon in the beginning, now train these models. Conduct preliminary evaluations to see if using said models are even feasible, before potentially wasting time tuning a model thats no-good."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(criterion='gini')\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2626   1773    600    176]\n",
      " [  1955 467541  19358  17581]\n",
      " [   668  16951  10287   3150]\n",
      " [   188  13445   2764  10006]]\n",
      "---------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.51      0.49      5175\n",
      "           2       0.94      0.92      0.93    506435\n",
      "           3       0.31      0.33      0.32     31056\n",
      "           4       0.32      0.38      0.35     26403\n",
      "\n",
      "    accuracy                           0.86    569069\n",
      "   macro avg       0.51      0.54      0.52    569069\n",
      "weighted avg       0.87      0.86      0.87    569069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, dt_pred))\n",
    "print('---------------------------------')\n",
    "print(classification_report(y_test, dt_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier()\n",
    "ada_clf.fit(X_train, y_train)\n",
    "ada_pred = ada_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1032   4128     15      0]\n",
      " [   667 505429    317     22]\n",
      " [   194  30655    193     14]\n",
      " [    36  26283     47     37]]\n",
      "---------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.20      0.29      5175\n",
      "           2       0.89      1.00      0.94    506435\n",
      "           3       0.34      0.01      0.01     31056\n",
      "           4       0.51      0.00      0.00     26403\n",
      "\n",
      "    accuracy                           0.89    569069\n",
      "   macro avg       0.57      0.30      0.31    569069\n",
      "weighted avg       0.84      0.89      0.84    569069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, ada_pred))\n",
    "print('---------------------------------')\n",
    "print(classification_report(y_test, ada_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/Programs/car-accident-analysis/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:709: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "kn_clf = MLPClassifier(max_iter=200)\n",
    "kn_clf.fit(X_train, y_train)\n",
    "kn_pred = kn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, kn_pred))\n",
    "print('---------------------------------')\n",
    "print(classification_report(y_test, kn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5) Hyperparameter Tuning\n",
    "For promising models, tune them even further to squeeze out the best possible performance. Some questions to consider.\n",
    "\n",
    "1. What hyperparamaters should I tune? Why?\n",
    "2. What values ranges should I choose for each param? Why?\n",
    "3. Should I use try the values manually, or use the [built-in tuning functions](https://scikit-learn.org/stable/modules/grid_search.html)?\n",
    "\n",
    "**Make sure to only tune on the training dataset!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def find_best_hyperparameters_m1(X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Input: The training X features and Y labels/values\n",
    "    Output: The classifier with the best hyperparams and the predictions\n",
    "    \"\"\"\n",
    "    clf = None # Create your base classifier\n",
    "    param_grid = {\"param_1\": [0, 1, 2],\n",
    "                  \"param_2\": ['value1', 'value2']}\n",
    "    \n",
    "    search = GridSearchCV(clf, param_grid)\n",
    "    search.fit(X_train,y_train)\n",
    "    return search, search.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it All Together\n",
    "\n",
    "Now, combine the \"scratch work\" that you did above into a tidy function that someone could use to replicate your work and process in a single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model1(X_train, X_test, Y_train, Y_test):\n",
    "    (X_train, X_test) = apply_feature_transformation(X_train, X_test)\n",
    "    (X_train, Y_train) = sample_data(X_train, Y_train)\n",
    "    hyperparameters = find_best_hyperparameters_m1(X_train, Y_train)\n",
    "    # Fit your model here\n",
    "    \n",
    "    # Return your model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model2(X_train, X_test, Y_train, Y_test):\n",
    "    (X_train, X_test) = apply_feature_transformation(X_train, X_test)\n",
    "    (X_train, Y_train) = sample_data(X_train, Y_train)\n",
    "    # You need to create a new hyperparameter selector for your second model, or remove this step\n",
    "    hyperparameters = find_best_hyperparameters_m2(X_train, Y_train)\n",
    "    # Fit your model here\n",
    "    \n",
    "    # Return your model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model3(X_train, X_test, Y_train, Y_test):\n",
    "    (X_train, X_test) = apply_feature_transformation(X_train, X_test)\n",
    "    (X_train, Y_train) = sample_data(X_train, Y_train)\n",
    "    # You need to create a new hyperparameter selector for your second model, or remove this step\n",
    "    hyperparameters = find_best_hyperparameters_m3(X_train, Y_train)\n",
    "    # Fit your model here\n",
    "    \n",
    "    # Return your model's predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "87be2dcbbb79fc5506227fc590a1a12ce1806d2d38b4e15620a5dad3eddc0f74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
